# Projeto: OtimizaÃ§Ã£o de HiperparÃ¢metros para PrediÃ§Ã£o de CBR

> Este projeto utiliza um Algoritmo GenÃ©tico (AG) para otimizar os hiperparÃ¢metros de modelos de Machine Learning (Rede Neural MLP e Random Forest) com o objetivo de prever o valor do California Bearing Ratio (CBR) de solos.

---

## ğŸ“– Fonte dos Dados e Tratamento

O conjunto de dados utilizado neste projeto foi extraÃ­do do estudo de doutorado de **JosÃ© Gustavo Hermida de Mello Ferreira**, conforme a referÃªncia abaixo:

> FERREIRA, JOSÃ‰ GUSTAVO HERMIDA DE MELLO. **Tratamento de Dados GeotÃ©cnicos Para PrediÃ§Ã£o de MÃ³dulos de ResiliÃªncia de Solos e Britas Utilizando Ferramentas de Data Mining**. Tese (D.Sc., Engenharia Civil) - COPPE/UFRJ, Rio de Janeiro, 2008.

O dataset original, contendo 463 amostras, passou por um processo de tratamento e curadoria para esta anÃ¡lise. As variÃ¡veis foram renomeadas para maior clareza (e.g., `CH`, `IP`, `CBR`). Para cada experimento, um subconjunto especÃ­fico de features Ã© selecionado (conforme definido em `config.py`). Subsequentemente, todas as amostras (linhas) que continham valores ausentes (`NaN`) em qualquer uma das colunas selecionadas foram removidas (`dropna()`) para garantir a qualidade e a integridade dos dados de entrada para os modelos.

## ğŸ”¬ Metodologia

A metodologia central deste trabalho consiste em aplicar tÃ©cnicas de otimizaÃ§Ã£o e aprendizado de mÃ¡quina para prever o California Bearing Ratio (CBR) de solos. Utiliza-se um **Algoritmo GenÃ©tico (AG)** para explorar um vasto espaÃ§o de hiperparÃ¢metros e encontrar a configuraÃ§Ã£o Ã³tima para dois modelos de regressÃ£o:

1.  **Rede Neural Artificial (MLP - Multi-Layer Perceptron)**
2.  **Random Forest (Floresta AleatÃ³ria)**

O framework Ã© projetado para executar esses experimentos de forma sistemÃ¡tica, registrando mÃ©tricas de performance, logs detalhados e visualizaÃ§Ãµes para cada execuÃ§Ã£o, permitindo uma anÃ¡lise comparativa robusta entre os modelos.

---

## ğŸš€ Tecnologias Utilizadas

* **Python 3.10+**
* **PyTorch**: Para a construÃ§Ã£o e treino do modelo de Rede Neural (MLP).
* **Scikit-learn**: Para o modelo Random Forest, prÃ©-processamento de dados e mÃ©tricas de avaliaÃ§Ã£o.
* **Pandas & NumPy**: Para manipulaÃ§Ã£o e anÃ¡lise de dados.
* **Rich**: Para a criaÃ§Ã£o de saÃ­das visualmente agradÃ¡veis no terminal.
* **Tqdm**: Para a exibiÃ§Ã£o de barras de progresso.
* **Matplotlib & Seaborn**: Para a geraÃ§Ã£o de grÃ¡ficos de anÃ¡lise.

---

## ğŸ“‚ Estrutura do Projeto

O projeto Ã© organizado com a seguinte estrutura para garantir a separaÃ§Ã£o de responsabilidades:

- **PROJETOFINAL/**
  - ğŸ“‚ **data/**
    - `SEU_ARQUIVO_DE_DADOS.xlsx`
  - ğŸ“‚ **models/**
    - `__init__.py`
    - `mlp_space.py` _(Define a arquitetura e o espaÃ§o de busca da MLP)_
    - `rf_space.py` _(Define o espaÃ§o de busca do Random Forest)_
  - ğŸ“‚ **notebooks_de_analise/**
    - `analise_shap.ipynb` _(Notebook para anÃ¡lise de interpretabilidade)_
  - ğŸ“‚ **optimization/**
    - `__init__.py`
    - `ga_tuner.py` _(ContÃ©m a classe do Algoritmo GenÃ©tico)_
  - ğŸ“‚ **results/** _(Gerada automaticamente)_
    - `run_YYYY-MM-DD_HH-MM-SS/`
      - `run_log.jsonl` _(Log detalhado em formato JSON)_
      - `*.png` _(GrÃ¡ficos de resultados)_
  - ğŸ“‚ **venv/** _(Ignorada pelo .gitignore)_
  - ğŸ“„ `analysis.py` _(MÃ³dulo para anÃ¡lise e plotagem final)_
  - ğŸ“„ `config.py` _(Painel de controle para configurar o experimento)_
  - ğŸ“„ `data_loader.py` _(MÃ³dulo para carregar e preparar os dados)_
  - ğŸ“„ `evaluation.py` _(LÃ³gica de avaliaÃ§Ã£o dos modelos)_
  - ğŸ“„ `main.py` _(Ponto de entrada principal para executar o projeto)_
  - ğŸ“„ `.gitignore` _(Arquivos e pastas a serem ignorados pelo Git)_
  - ğŸ“„ `README.md` _(Este arquivo)_
  - ğŸ“„ `requirements.txt` _(Lista de dependÃªncias do Python)_

---

## âš™ï¸ Como Executar o Projeto (Passo a Passo)

Este guia foi feito para um ambiente **Linux (Ubuntu / WSL)**.

### PrÃ©-requisitos
* Git
* Python 3.10 ou superior
* Acesso a um terminal (shell) Bash.

### Passo 1: Clonar o RepositÃ³rio
Primeiro, clone este repositÃ³rio para a sua mÃ¡quina local.

```bash
git clone [https://github.com/iagoLopex/TCC.git](https://github.com/iagoLopex/TCC.git)
cd TCC
Passo 2: Configurar o Ambiente Virtual (venv)
Ã‰ crucial usar um ambiente virtual para isolar as dependÃªncias do projeto.

Bash

# 1. Garanta que o pacote python3-venv estÃ¡ instalado (para Debian/Ubuntu)
sudo apt update && sudo apt install python3-venv -y

# 2. Crie o ambiente virtual na pasta do projeto
python3 -m venv venv

# 3. Ative o ambiente virtual
source venv/bin/activate
ApÃ³s a ativaÃ§Ã£o, vocÃª verÃ¡ (venv) no inÃ­cio do prompt do seu terminal.

Passo 3: Instalar as DependÃªncias
Instale todas as bibliotecas necessÃ¡rias listadas no requirements.txt.

Bash

# Opcional, mas recomendado: atualize o pip
pip install --upgrade pip

# Instale os pacotes
pip install -r requirements.txt
Passo 4: Configurar o Experimento
Antes de executar, vocÃª pode customizar o experimento editando o arquivo config.py. Nele, vocÃª pode alterar:

O modelo a ser otimizado (MODEL_TO_OPTIMIZE).
O conjunto de dados a ser usado (DATASET).
O mÃ©todo de validaÃ§Ã£o (VALIDATION_METHOD).
Os parÃ¢metros do Algoritmo GenÃ©tico (GA_PARAMS).
Passo 5: Executar a OtimizaÃ§Ã£o
Com tudo pronto, basta executar o script principal.

Bash

python3 main.py
O script comeÃ§arÃ¡ a otimizaÃ§Ã£o. VocÃª verÃ¡ o progresso no terminal e, ao final, uma nova pasta serÃ¡ criada dentro de results/ com todos os logs e grÃ¡ficos da execuÃ§Ã£o.

Passo 6: Desativar o Ambiente
Quando terminar de trabalhar no projeto, vocÃª pode desativar o ambiente virtual.

Bash

deactivate
ğŸ“Š AnÃ¡lise dos Resultados
ApÃ³s cada execuÃ§Ã£o, navegue atÃ© a pasta results/ e encontre a subpasta nomeada com a data e hora da sua execuÃ§Ã£o (ex: run_2025-06-17_14-45-00/). Dentro dela, vocÃª encontrarÃ¡:

run_log.jsonl: Um arquivo com o log completo e detalhado de cada geraÃ§Ã£o do algoritmo genÃ©tico, em formato JSON, ideal para anÃ¡lises programÃ¡ticas.
*.png: Os grÃ¡ficos de avaliaÃ§Ã£o do melhor modelo, como a curva de aprendizado e a anÃ¡lise de resÃ­duos, jÃ¡ salvos como imagens.
final_model.joblib ou final_model.pth: O objeto do modelo final treinado, pronto para ser carregado e usado em outras anÃ¡lises (como no notebook SHAP).
ğŸ‘¤ Autor
Iago Lopes

GitHub: iagoLopex
<!-- end list -->