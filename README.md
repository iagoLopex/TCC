# Projeto: OtimizaÃ§Ã£o de HiperparÃ¢metros para PrediÃ§Ã£o de CBR

> Este projeto utiliza um Algoritmo GenÃ©tico (AG) para otimizar os hiperparÃ¢metros de modelos de Machine Learning (MLP e Random Forest) visando prever o California Bearing Ratio (CBR) de solos.

---

## ğŸ“– Fonte dos Dados e Tratamento

O dataset original (463 amostras) foi extraÃ­do da tese de doutorado de **JosÃ© Gustavo Hermida de Mello Ferreira** (2008) e passou por:

1. RenomeaÃ§Ã£o de variÃ¡veis para maior clareza (`CH`, `IP`, `CBR`, etc.).
2. SeleÃ§Ã£o de subconjuntos de features via `config.py`.
3. RemoÃ§Ã£o de todas as linhas com valores ausentes (`dropna()`).

---

## ğŸ”¬ Metodologia

Aplicamos um **Algoritmo GenÃ©tico** para buscar a melhor configuraÃ§Ã£o de hiperparÃ¢metros em dois modelos de regressÃ£o:

1. **MLP (Multi-Layer Perceptron)**  
2. **Random Forest**

O pipeline executa cada experimento de forma sistemÃ¡tica, gerando:

- MÃ©tricas de performance
- Logs detalhados (JSONL)
- GrÃ¡ficos comparativos

---

## ğŸš€ Tecnologias Utilizadas

- **Python 3.10+**  
- **PyTorch** (MLP)  
- **Scikit-learn** (Random Forest, prÃ©-processamento, mÃ©tricas)  
- **Pandas & NumPy** (manipulaÃ§Ã£o de dados)  
- **Rich** (saÃ­das no terminal)  
- **Tqdm** (barras de progresso)  
- **Matplotlib & Seaborn** (visualizaÃ§Ãµes)  

---

## ğŸ“‚ Estrutura do Projeto

PROJETOFINAL/
â”œâ”€â”€ data/
â”‚ â””â”€â”€ SEU_ARQUIVO_DE_DADOS.xlsx
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ mlp_space.py # Define arquitetura e espaÃ§o de busca da MLP
â”‚ â””â”€â”€ rf_space.py # Define espaÃ§o de busca do Random Forest
â”œâ”€â”€ notebooks_de_analise/
â”‚ â””â”€â”€ analise_shap.ipynb # Notebook de interpretabilidade
â”œâ”€â”€ optimization/
â”‚ â”œâ”€â”€ init.py
â”‚ â””â”€â”€ ga_tuner.py # Classe do Algoritmo GenÃ©tico
â”œâ”€â”€ results/ # Gerada automaticamente
â”‚ â””â”€â”€ run_YYYY-MM-DD_HH-MM-SS/
â”‚ â”œâ”€â”€ run_log.jsonl # Log em JSONL
â”‚ â””â”€â”€ *.png # GrÃ¡ficos de resultados
â”œâ”€â”€ venv/ # Ignorado pelo .gitignore
â”œâ”€â”€ analysis.py # AnÃ¡lise e plotagem final
â”œâ”€â”€ config.py # Painel de controle do experimento
â”œâ”€â”€ data_loader.py # Carregamento e preparaÃ§Ã£o dos dados
â”œâ”€â”€ evaluation.py # LÃ³gica de avaliaÃ§Ã£o dos modelos
â”œâ”€â”€ main.py # Ponto de entrada principal
â”œâ”€â”€ .gitignore # Arquivos/pastas ignorados pelo Git
â”œâ”€â”€ README.md # Este arquivo
â””â”€â”€ requirements.txt # DependÃªncias Python

yaml
Copiar
Editar

---

## âš™ï¸ Como Executar o Projeto

Este guia assume **Linux (Ubuntu / WSL)**.

### PrÃ©-requisitos

- Git  
- Python 3.10+  
- Bash (terminal)

---

### Passo 1: Clonar o RepositÃ³rio

```bash
git clone https://github.com/iagoLopex/TCC.git
cd TCC
Passo 2: Configurar o Ambiente Virtual
Instalar venv (Debian/Ubuntu):

bash
Copiar
Editar
sudo apt update && sudo apt install python3-venv -y
Criar o venv:

bash
Copiar
Editar
python3 -m venv venv
Ativar o venv:

bash
Copiar
Editar
source venv/bin/activate
Passo 3: Instalar DependÃªncias
bash
Copiar
Editar
pip install --upgrade pip
pip install -r requirements.txt
Passo 4: Configurar o Experimento
Edite o config.py para ajustar:

MODEL_TO_OPTIMIZE

DATASET

VALIDATION_METHOD

GA_PARAMS

Passo 5: Executar a OtimizaÃ§Ã£o
bash
Copiar
Editar
python3 main.py
Ao final, uma nova pasta em results/ serÃ¡ criada com logs e grÃ¡ficos.

Passo 6: Desativar o Ambiente
bash
Copiar
Editar
deactivate
ğŸ“Š AnÃ¡lise dos Resultados
Acesse a pasta gerada em results/run_YYYY-MM-DD_HH-MM-SS/ e verifique:

run_log.jsonl: logs do AG por geraÃ§Ã£o

*.png: curvas de aprendizado, anÃ¡lises de resÃ­duos

final_model.joblib/.pth: modelo treinado para uso posterior

ğŸ‘¤ Autor
Iago Lopes
GitHub: iagoLopex