# Otimiza√ß√£o de Hiperpar√¢metros com Algoritmo Gen√©tico: Uma An√°lise Comparativa entre Artificial Neural Networks e Random Forest para Predi√ß√£o do √çndice de Suporte Calif√≥rnia

> Este projeto utiliza um Algoritmo Gen√©tico (AG) para otimizar os hiperpar√¢metros de modelos de Machine Learning (Rede Neural MLP e Random Forest) com o objetivo de prever o valor do California Bearing Ratio (CBR) de solos.

---

## üìñ Fonte dos Dados e Tratamento

O conjunto de dados utilizado neste projeto foi extra√≠do do estudo de doutorado de **Jos√© Gustavo Hermida de Mello Ferreira**, conforme a refer√™ncia abaixo:

> FERREIRA, JOS√â GUSTAVO HERMIDA DE MELLO. **Tratamento de Dados Geot√©cnicos Para Predi√ß√£o de M√≥dulos de Resili√™ncia de Solos e Britas Utilizando Ferramentas de Data Mining**. Tese (D.Sc., Engenharia Civil) - COPPE/UFRJ, Rio de Janeiro, 2008.

O dataset original, contendo 463 amostras, passou por um processo de tratamento e curadoria para esta an√°lise, restando algo entorno de 330 amostras que possuem o CBR n√£o nulo. As vari√°veis foram renomeadas para maior clareza (e.g., `CH`, `IP`, `CBR`). Para cada experimento, um subconjunto espec√≠fico de features √© selecionado (conforme definido em `config.py`). Subsequentemente, todas as amostras (linhas) que continham valores ausentes (`NaN`) em qualquer uma das colunas selecionadas foram removidas (`dropna()`) para garantir a qualidade e a integridade dos dados de entrada para os modelos.

## An√°lise breve do dataset

A vari√°vel target CBR nessa base de dados, com rela√ß√£o √† quantidade de amostras, est√° mal distribu√≠da no intervalo de 1 at√© 155, o que leva a problemas iniciais de treinamento dos modelos.

![Image](https://github.com/user-attachments/assets/522970d4-d667-46ae-ab90-552a991eaba4)

>A proposta utilizada √© a possibilidade de atribui√ß√£o de pesos para as amostras de CBR que tem o valor maior que um valor fixo que o usu√°rio definir (Google Developers, 2025), para uma an√°lise mais profunda de como o modelo lida com estes testes.

## üìö Refer√™ncias
* YABI, C. P. et al. **Prediction of CBR by Deep Artificial Neural Networks with Hyperparameter Optimization by Simulated Annealing**. Indian Geotechnical Journal, v. 54, n. 1, p. 121-137, fev. 2024. Dispon√≠vel em: <https://doi.org/10.1007/s40098-024-00870-4>. Acesso em: 3 jun. 2025.

* TADO, N.; MEDIHAJIT, S.; PAL, D. **Forecasting California bearing ratio (CBR) of soil using machine learning algorithms: A review**. Research on Engineering Structures and Materials and Materials, v. 11, n. 1, p. 383-398, 2025. Dispon√≠vel em: <http://dx.doi.org/10.17515/resm2025-623ml0115rv>. Acesso em: 3 jun. 2025.

* Google Developers. (s.d.). **Conjuntos de dados desequilibrados**. Machine Learning Crash Course. Dispon√≠vel em: <https://developers.google.com/machine-learning/crash-course/classification/handling-imbalanced-classes>. Acesso em: 5 jun. 2025.

* BERNUCCI, Liedi Bariani et al. **Pavimenta√ß√£o asf√°ltica: forma√ß√£o b√°sica para engenheiros**. 2. ed. Rio de Janeiro: Petrobras, 2022.

* ORTEGA, Julio Bizarreta; AVEROS, Sara Ochoa. **Manual Did√°tico para a Execu√ß√£o do Ensaio √çndice de Suporte Calif√≥rnia (ISC)**. Foz do Igua√ßu: Edunila, 2022.

## üî¨ Metodologia

A metodologia central deste trabalho consiste em aplicar t√©cnicas de otimiza√ß√£o e aprendizado de m√°quina para prever o California Bearing Ratio (CBR) de solos. Utiliza-se um **Algoritmo Gen√©tico (AG)** para explorar um vasto espa√ßo de hiperpar√¢metros e encontrar a configura√ß√£o √≥tima para dois modelos de regress√£o:

1.  **Rede Neural Artificial (MLP - Multi-Layer Perceptron)**
2.  **Random Forest (Floresta Aleat√≥ria)**

>O framework √© projetado para executar esses experimentos de forma sistem√°tica, registrando m√©tricas de performance, logs detalhados e visualiza√ß√µes para cada execu√ß√£o, permitindo uma an√°lise comparativa robusta entre os modelos.

![Image](https://github.com/user-attachments/assets/0382240d-1163-43be-9d6c-810b9c30139a)


>Esse fluxograma apresenta a metodologia de testes que o usu√°rio pode efetuar com base nas decis√µes do mesmo, como escolha de configura√ß√£o dos dados de entrada com base no dataset dado (representado pelos Datasets 1, 2 e 3), atribui√ß√£o ou n√£o de pesos para algumas vari√°veis, e escolha do m√©todo de cross-validation (K-fold ou Holdout).

Exemplo de configura√ß√µes de datasets (a partir do feature selection):

![Image](https://github.com/user-attachments/assets/4029f516-3bb9-496b-882b-4bacacad2b24)

---

## üöÄ Tecnologias Utilizadas

* **Python 3.10+**
* **PyTorch**: Para a constru√ß√£o e treino do modelo de Rede Neural (MLP).
* **Scikit-learn**: Para o modelo Random Forest, pr√©-processamento de dados e m√©tricas de avalia√ß√£o.
* **Pandas & NumPy**: Para manipula√ß√£o e an√°lise de dados.
* **Rich**: Para a cria√ß√£o de sa√≠das visualmente agrad√°veis no terminal.
* **Tqdm**: Para a exibi√ß√£o de barras de progresso.
* **Matplotlib & Seaborn**: Para a gera√ß√£o de gr√°ficos de an√°lise.

---

## üìÇ Estrutura do Projeto

O projeto √© organizado com a seguinte estrutura para garantir a separa√ß√£o de responsabilidades:

- **PROJETOFINAL/**
  - üìÇ **data/**
    - `SEU_ARQUIVO_DE_DADOS.xlsx`
  - üìÇ **models/**
    - `__init__.py`
    - `mlp_space.py` _(Define a arquitetura e o espa√ßo de busca da MLP)_
    - `rf_space.py` _(Define o espa√ßo de busca do Random Forest)_
  - üìÇ **notebooks_de_analise/**
    - `analise_shap.ipynb` _(Notebook para an√°lise de interpretabilidade)_
  - üìÇ **optimization/**
    - `__init__.py`
    - `ga_tuner.py` _(Cont√©m a classe do Algoritmo Gen√©tico)_
  - üìÇ **results/** _(Gerada automaticamente)_
    - `run_YYYY-MM-DD_HH-MM-SS/`
      - `run_log.jsonl` _(Log detalhado em formato JSON)_
      - `*.png` _(Gr√°ficos de resultados)_
  - üìÇ **venv/** _(Ignorada pelo .gitignore)_
  - üìÑ `analysis.py` _(M√≥dulo para an√°lise e plotagem final)_
  - üìÑ `config.py` _(Painel de controle para configurar o experimento)_
  - üìÑ `data_loader.py` _(M√≥dulo para carregar e preparar os dados)_
  - üìÑ `evaluation.py` _(L√≥gica de avalia√ß√£o dos modelos)_
  - üìÑ `main.py` _(Ponto de entrada principal para executar o projeto)_
  - üìÑ `.gitignore` _(Arquivos e pastas a serem ignorados pelo Git)_
  - üìÑ `README.md` _(Este arquivo)_
  - üìÑ `requirements.txt` _(Lista de depend√™ncias do Python)_

---

## ‚öôÔ∏è Como Executar o Projeto (Passo a Passo)

Este guia foi feito para um ambiente **Linux (Ubuntu / WSL)**.

### Pr√©-requisitos
* Git
* Python 3.10 ou superior
* Acesso a um terminal (shell) Bash.

### Passo 1: Clonar o Reposit√≥rio
Primeiro, clone este reposit√≥rio para a sua m√°quina local.

```bash
# clone do reposit√≥rio
git clone https://github.com/iagoLopex/TCC.git

# entrar nele
cd TCC
```

### Passo 2: Configurar o Ambiente Virtual (venv) (√â crucial usar um ambiente virtual para isolar as depend√™ncias do projeto)


```bash
# 1. Garanta que o pacote python3-venv est√° instalado (para Debian/Ubuntu)
sudo apt update && sudo apt install python3-venv -y

# 2. Crie o ambiente virtual na pasta do projeto
python3 -m venv venv

# 3. Ative o ambiente virtual
source venv/bin/activate
```
Ap√≥s a ativa√ß√£o, voc√™ ver√° (venv) no in√≠cio do prompt do seu terminal.

### Passo 3: Instalar as Depend√™ncias (Instale todas as bibliotecas necess√°rias listadas no requirements.txt)

```bash
# Opcional, mas recomendado: atualize o pip
pip install --upgrade pip

# Instale os pacotes
pip install -r requirements.txt
```

### Passo 4: Configurar o Experimento (Antes de executar, voc√™ pode customizar o experimento editando o arquivo config.py. Nele, voc√™ pode alterar)

 - O modelo a ser otimizado (MODEL_TO_OPTIMIZE).
 - O conjunto de dados a ser usado (DATASET).
 - O m√©todo de valida√ß√£o (VALIDATION_METHOD).
 - Os par√¢metros do Algoritmo Gen√©tico (GA_PARAMS).
 - Passo 5: Executar a Otimiza√ß√£o
 - Com tudo pronto, basta executar o script principal.

```bash
python3 main.py
```

>O script come√ßar√° a otimiza√ß√£o. Voc√™ ver√° o progresso no terminal e, ao final, uma nova pasta ser√° criada dentro de results/ com todos os logs e gr√°ficos da execu√ß√£o:


![Image](https://github.com/user-attachments/assets/7f96e19a-5100-4fac-a7c8-bae62bf89b13)


## üìä An√°lise dos Resultados

>Ap√≥s cada execu√ß√£o, navegue at√© a pasta results/ e encontre a subpasta nomeada com a data e hora da sua execu√ß√£o (ex: run_2025-06-17_14-45-00/). Dentro dela, voc√™ encontrar√°:

- run_log.jsonl: Um arquivo com o log completo e detalhado de cada gera√ß√£o do algoritmo gen√©tico, em formato JSON e os hiperpar√¢metros utilizados.
- *.png: Os gr√°ficos de avalia√ß√£o do melhor modelo, como a curva de aprendizado e a an√°lise de res√≠duos, j√° salvos como imagens.
- final_model.joblib ou final_model.pth: O objeto do modelo final treinado, pronto para ser carregado e usado em outras an√°lises (como no notebooks_analysis).

![Image](https://github.com/user-attachments/assets/029a8a76-2144-42de-bd01-7a4a863ce689)

## üí° Dando Continuidade ao Projeto
A estrutura modular foi projetada para facilitar a expans√£o.

>Para Adicionar um Novo Modelo (ex: Gradient Boosting):
 1. Crie o Arquivo: Crie um novo arquivo models/gb_space.py.
 2. Implemente a Classe: Dentro dele, crie uma classe GradientBoostingSpace seguindo a mesma estrutura da MLPBlockSpace ou RandomForestSpace. Ela precisa ter os atributos bounds e types, e os m√©todos decode e evaluate.
 3. Registre o Modelo: No arquivo evaluation.py, importe sua nova classe e adicione-a ao dicion√°rio MODEL_CLASSES:

```Python
MODEL_CLASSES = {"MLP": MLPBlockSpace, "RF": RandomForestSpace, "GB": GradientBoostingSpace}
```
 4. Configure e Rode: No config.py, mude MODEL_TO_OPTIMIZE = "GB" e execute o main.py.

>Para Testar um Novo Conjunto de Features:
 1. Edite o data_loader.py: Adicione uma nova entrada ao dicion√°rio column_map, por exemplo, 'D4', com a lista de colunas desejada.
 2. Configure e Rode: No config.py, mude DATASET = "D4" e execute o main.py.

üë§ Autor
Iago de Souza Lopes

GitHub: iagoLopex
<!-- end list -->